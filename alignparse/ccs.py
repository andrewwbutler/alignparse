"""
===
ccs
===

Tools for inspecting output of the PacBio ``ccs`` program:
https://github.com/PacificBiosciences/unanimity/blob/develop/doc/PBCCS.md

"""


import collections
import io
import os
import re
import tempfile  # noqa: F401
import textwrap  # noqa: F401

import numpy

import pandas as pd

import plotnine as p9

import pysam

from alignparse.constants import CBPALETTE


class Summary:
    """Summary of a single ``ccs`` run.

    Parameters
    ----------
    name : str
        Name of the ``ccs`` run.
    fastqfile : str
        FASTQ file with circular consensus sequences, generated from BAM output
        of ``ccs`` with ``samtools bam2fq -T np,rq {bamfile} > {fastqfile}``.
        Can be gzipped.
    reportfile : str
        Report file generated by ``ccs`` using ``--reportFile`` flag.

    Attributes
    ----------
    name : str
        Name of ``ccs`` run.
    fastqfile : str
        FASTQ file with the circular consensus sequences.
    reportfile : str
        ``ccs`` report file.
    zmw_stats : pandas.DataFrame
        Stats on ZMW extracted from `reportfile`.
    passes : numpy.array
        Lists number of passes for all circular consensus sequences.
    quals : numpy.array
        Lists predicted quality for all circular consensus sequences.
    lengths : numpy.array
        Lists lengths for all circular consensus sequences.

    """

    def __init__(self, *, name, fastqfile, reportfile):
        """See main class docstring."""
        self.name = name
        for f, attr in [(fastqfile, 'fastqfile'), (reportfile, 'reportfile')]:
            if not os.path.isfile(f):
                raise IOError(f"cannot find `{attr}` {f}")
            setattr(self, attr, f)

        self.zmw_stats = report_to_stats(self.reportfile, stat_type='zmw')

        ccs_stats = get_ccs_stats(self.fastqfile)
        self.passes = ccs_stats.passes
        self.quals = ccs_stats.quals
        self.lengths = ccs_stats.lengths
        assert len(self.passes) == len(self.quals) == len(self.lengths)
        if len(self.passes) != (self.zmw_stats
                                .set_index('status')
                                .at['Success -- CCS generated', 'number']):
            raise ValueError('`fastqfile` and `reportfile` differ on number '
                             'of circular consensus sequences generated.')


class Summaries:
    """Summaries of ``ccs`` runs.

    Parameters
    ----------
    df : pandas.DataFrame
        Data frame giving information on runs of ``ccs`` being summarized.
    name_col : str
        Column in `df` with name of ``ccs`` run.
    fastq_col : str
        Column in `df` with FASTQ file for run, appropriate for passing
        to :class:`Summary` as `fastqfile`.
    report_col : str
        Column in `df` with report for run, appropriate for passing
        to :class:`Summary` as `reportfile`.

    Attributes
    ----------
    summaries : list
        List of :class:`Summary` objects for each run.

    """

    def __init__(self, df, *,
                 name_col='name', fastq_col='fastq', report_col='report'):
        """See main class docstring."""
        cols = [name_col, fastq_col, report_col]
        if len(cols) != len(set(cols)):
            raise ValueError(f"repeated column names in `df`")
        for col in cols:
            if col not in df.columns:
                raise ValueError(f"`df` lacks column {col}")

        if len(df[name_col]) != len(df[name_col].unique()):
            raise ValueError(f"the run names in {name_col} are not unique")

        self.summaries = []
        for tup in df.itertuples(index=False):
            self.summaries.append(
                Summary(name=getattr(tup, name_col),
                        fastqfile=getattr(tup, fastq_col),
                        reportfile=getattr(tup, report_col)
                        )
                )

    def zmw_plot(self, *, minfrac=0.01):
        """Plot of ZMW stats for each run.

        Parameters
        ----------
        minfrac : float
            Group failure categories with <= this fraction ZMWs for all runs.

        Returns
        -------
        plotnine.ggplot.ggplot
            Stacked bar graph of ZMW stats for each run.

        """
        df = self.zmw_stats(minfrac=minfrac)

        p = (p9.ggplot(df, p9.aes(x='name', y='number', fill='status')) +
             p9.geom_col(position=p9.position_stack(reverse=True), width=0.8) +
             p9.theme(axis_text_x=p9.element_text(angle=90,
                                                  vjust=1,
                                                  hjust=0.5),
                      figure_size=(0.4 * len(df['name'].unique()), 2.5)
                      ) +
             p9.ylab('number of ZMWs') +
             p9.xlab('')
             )

        if len(df['status'].unique()) < len(CBPALETTE):
            p = p + p9.scale_fill_manual(CBPALETTE[1:])

        return p

    def zmw_stats(self, *, minfrac=0.01):
        """
        Parameters
        ----------
        minfrac : float
            Group failure categories with <= this fraction ZMWs for all runs.

        Returns
        -------
        pandas.DataFrame
            Data frame with stats for all runs.

        """
        df = (pd.concat([summary.zmw_stats.assign(name=summary.name)
                         for summary in self.summaries])
              [['name', 'status', 'number', 'fraction']]
              .assign(max_fraction=lambda x: (x.groupby('status')
                                              ['fraction']
                                              .transform(max)
                                              ),
                      failed=lambda x: x['status'].str.contains('Failed'),
                      other=lambda x: (x['max_fraction'] < minfrac) & x.failed
                      )
              )

        other_df = (df.query('other')
                    .groupby('name')
                    .aggregate({'number': sum, 'fraction': sum, 'failed': any})
                    .assign(status='Failed -- Other reason')
                    .reset_index()
                    .assign(max_fraction=lambda x: (x.groupby('status')
                                                    ['fraction']
                                                    .transform(max)
                                                    ))
                    )

        df = (df
              .query('not other')
              .drop(columns='other')
              .merge(other_df, how='outer')
              )

        # order columns
        names = [summary.name for summary in self.summaries]
        statuses = (df
                    .sort_values(['failed', 'max_fraction'],
                                 ascending=[True, False])
                    ['status']
                    .unique()
                    )
        df = (df
              .assign(name=lambda x: pd.Categorical(x['name'],
                                                    names,
                                                    ordered=True),
                      status=lambda x: pd.Categorical(x['status'],
                                                      statuses,
                                                      ordered=True),
                      )
              .sort_values(['name', 'status'])
              .drop(columns=['max_fraction', 'failed'])
              .reset_index(drop=True)
              )

        return df


def report_to_stats(reportfile, *, stat_type='zmw'):
    """Parse statistics from report file.

    Parameters
    ----------
    reportfile : str
        Report file generatedy by ``ccs`` using ``--reportFile`` flag.
    stat_type : {'zmw', 'subread'}
        Get stats on ZMWs or subreads.

    Returns
    -------
    pandas.DataFrame
        A data frame with the statistics.

    Example
    -------

    >>> reportfile = tempfile.NamedTemporaryFile(mode='w')
    >>> _ = reportfile.write(textwrap.dedent('''
    ...     ZMW Yield
    ...     Success -- CCS generated,242220,45.57%
    ...     Failed -- Below SNR threshold,0,0.00%
    ...     Failed -- No usable subreads,4877,0.92%
    ...     Failed -- Insert size too long,35,0.00%
    ...     Failed -- Insert size too small,0,0.00%
    ...     Failed -- Not enough full passes,180620,33.98%
    ...     Failed -- Too many unusable subreads,1,0.00%
    ...     Failed -- CCS did not converge,23,0.00%
    ...     Failed -- CCS below minimum predicted accuracy,103801,19.53%
    ...     Failed -- Unknown error during processing,0,0.00%
    ...
    ...
    ...     Subread Yield
    ...     Success - Used for CCS,10972010,89.06%
    ...     Failed -- Below SNR threshold,0,0.00%
    ...     Failed -- Alpha/Beta mismatch,171,0.00%
    ...     Failed -- Below minimum quality,0,0.00%
    ...     Failed -- Filtered by size,144209,1.17%
    ...     Failed -- Identity too low,2745750,22.29%
    ...     Failed -- Z-Score too low,0,0.00%
    ...     Failed -- From ZMW with too few passes,274296,2.23%
    ...     Failed -- Other,928871,7.54%
    ...     ''').lstrip())
    >>> reportfile.flush()
    >>> report_to_stats(reportfile.name)
                                               status  number percent  fraction
    0                        Success -- CCS generated  242220  45.57%    0.4557
    1                   Failed -- Below SNR threshold       0   0.00%    0.0000
    2                    Failed -- No usable subreads    4877   0.92%    0.0092
    3                  Failed -- Insert size too long      35   0.00%    0.0000
    4                 Failed -- Insert size too small       0   0.00%    0.0000
    5                Failed -- Not enough full passes  180620  33.98%    0.3398
    6            Failed -- Too many unusable subreads       1   0.00%    0.0000
    7                  Failed -- CCS did not converge      23   0.00%    0.0000
    8  Failed -- CCS below minimum predicted accuracy  103801  19.53%    0.1953
    9       Failed -- Unknown error during processing       0   0.00%    0.0000
    >>> reportfile.close()

    """
    reportmatch = re.compile('^ZMW Yield\n(?P<zmw>(.+\n)+)\n\n'
                             'Subread Yield\n(?P<subread>(.+\n)+)$')
    with open(reportfile) as f:
        report = f.read()
    m = reportmatch.search(report)
    if not m:
        raise ValueError(f"Cannot match report in {reportfile}:\n{report}")

    return (pd.read_csv(io.StringIO(m.group(stat_type)),
                        names=['status', 'number', 'percent'])
            .assign(fraction=lambda x: (x.percent.str.slice(None, -1)
                                        .astype(float) / 100))
            )


def get_ccs_stats(fastqfile, *, pass_tag='np', qual_tag='rq'):
    """Get basic statistics about circular consensus sequences.

    Parameters
    ----------
    fastqfile : str
        FASTQ file with circular consensus sequences, generated from BAM output
        of ``ccs`` with ``samtools bam2fq -T np,rq {bamfile} > {fastqfile}``.
        Can be gzipped.
    pass_tag : str
        Tag in FASTQ file giving number of passes.
    qual_tag : str
        Tag in FASTQ file giving predicted sequence quality.

    Returns
    -------
    collections.namedtuple
        The 3-tuple `(passes, quals, lengths)`, which contains numpy arrays
        giving number of passes, qualities, and lengths for sequences in
        `fastqfile`.

    Example
    -------
    >>> fastqfile = tempfile.NamedTemporaryFile(mode='w')
    >>> _ = fastqfile.write(textwrap.dedent('''
    ...   @m54228_190118_102822/4194373/ccs np:i:18 rq:f:0.999998
    ...   GGTACCACACTCTTTCCCTACACGACGCTCTGCCGATCTCGGCCATTACGTGTTTTATCTA
    ...   +
    ...   ~~~~{~~~~~~~c~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~i~~~~~~~~
    ...   @m54228_190118_102822/4194374/ccs np:i:51 rq:f:1
    ...   GCACGGCGTCACACTTTGCTATGCCATAGCATGTTTATCCATAAGATTAGCGGATCCTACCT
    ...   +
    ...   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    ...   ''').lstrip())
    >>> fastqfile.flush()
    >>> get_ccs_stats(fastqfile.name)  # doctest: +NORMALIZE_WHITESPACE
    CCS_Stats(passes=array([18, 51]),
              quals=array([0.999998, 1.      ]),
              lengths=array([61, 62]))
    >>> fastqfile.close()

    """
    matchers = {'pass': re.compile(r'(?:^|\s)'  # start of str or space
                                   rf"{pass_tag}:i:(?P<pass>\d+)"
                                   r'(?:\s|$)'  # end of str or space
                                   ),
                'qual': re.compile(r'(?:^|\s)'  # start of str or space
                                   rf"{qual_tag}:f:(?P<qual>\d+(?:\.\d+)?)"
                                   r'(?:\s|$)'  # end of str or space
                                   ),
                }
    arrays = {'pass': [], 'qual': [], 'length': []}
    for rec in pysam.FastxFile(fastqfile):
        for mtype, matcher in matchers.items():
            m = matcher.search(rec.comment)
            if not m:
                raise ValueError(f"no `{mtype}_tag`:\n{rec}\n\n{rec.comment}")
            arrays[mtype].append(m.group(mtype))
        arrays['length'].append(len(rec.sequence))

    CCS_Stats = collections.namedtuple('CCS_Stats', 'passes quals lengths')
    return CCS_Stats(passes=numpy.array(arrays['pass'], dtype='int'),
                     quals=numpy.array(arrays['qual'], dtype='float'),
                     lengths=numpy.array(arrays['length'], dtype='int'),
                     )


if __name__ == '__main__':
    import doctest
    doctest.testmod()
