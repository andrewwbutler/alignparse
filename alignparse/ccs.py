"""
===
ccs
===

Tools for inspecting output of the PacBio ``ccs`` program:
https://github.com/PacificBiosciences/unanimity/blob/develop/doc/PBCCS.md

"""


import collections
import io
import math
import os
import re
import tempfile  # noqa: F401
import textwrap  # noqa: F401

import numpy

import pandas as pd

import plotnine as p9

import pysam

from alignparse.constants import CBPALETTE


class Summary:
    """Summary of a single ``ccs`` run.

    Parameters
    ----------
    name : str
        Name of the ``ccs`` run.
    fastqfile : str
        FASTQ file with circular consensus sequences, generated from BAM output
        of ``ccs`` with ``samtools bam2fq -T np,rq {bamfile} > {fastqfile}``.
        Can be gzipped.
    reportfile : str
        Report file generated by ``ccs`` using ``--reportFile`` flag.

    Attributes
    ----------
    name : str
        Name of ``ccs`` run.
    fastqfile : str
        FASTQ file with the circular consensus sequences.
    reportfile : str
        ``ccs`` report file.
    zmw_stats : pandas.DataFrame
        Stats on ZMW extracted from `reportfile`.
    passes : numpy.array
        Lists number of passes for all circular consensus sequences.
    quals : numpy.array
        Lists predicted quality for all circular consensus sequences.
    lengths : numpy.array
        Lists lengths for all circular consensus sequences.

    """

    def __init__(self, *, name, fastqfile, reportfile):
        """See main class docstring."""
        self.name = name
        for f, attr in [(fastqfile, 'fastqfile'), (reportfile, 'reportfile')]:
            if not os.path.isfile(f):
                raise IOError(f"cannot find `{attr}` {f}")
            setattr(self, attr, f)

        self.zmw_stats = report_to_stats(self.reportfile, stat_type='zmw')

        ccs_stats = get_ccs_stats(self.fastqfile)
        self.passes = ccs_stats.passes
        self.quals = ccs_stats.quals
        self.lengths = ccs_stats.lengths
        assert len(self.passes) == len(self.quals) == len(self.lengths)
        zmw_stats_nccs = (self.zmw_stats
                          .query('status.str.match("^Success")')
                          ['number']
                          .sum()
                          )
        if len(self.passes) != zmw_stats_nccs:
            raise ValueError('`fastqfile` and `reportfile` differ on number '
                             f"of CCSs.\n{fastqfile} has {len(self.passes)}\n"
                             f"{reportfile} has {zmw_stats_nccs}")


class Summaries:
    """Summaries of ``ccs`` runs.

    Parameters
    ----------
    df : pandas.DataFrame
        Data frame giving information on runs of ``ccs`` being summarized.
    name_col : str
        Column in `df` with name of ``ccs`` run.
    fastq_col : str
        Column in `df` with FASTQ file for run, appropriate for passing
        to :class:`Summary` as `fastqfile`.
    report_col : str
        Column in `df` with report for run, appropriate for passing
        to :class:`Summary` as `reportfile`.

    Attributes
    ----------
    summaries : list
        List of :class:`Summary` objects for each run.

    """

    def __init__(self, df, *,
                 name_col='name', fastq_col='fastq', report_col='report'):
        """See main class docstring."""
        cols = [name_col, fastq_col, report_col]
        if len(cols) != len(set(cols)):
            raise ValueError(f"repeated column names in `df`")
        for col in cols:
            if col not in df.columns:
                raise ValueError(f"`df` lacks column {col}")

        if len(df[name_col]) != len(df[name_col].unique()):
            raise ValueError(f"the run names in {name_col} are not unique")

        self.summaries = []
        for tup in df.itertuples(index=False):
            self.summaries.append(
                Summary(name=getattr(tup, name_col),
                        fastqfile=getattr(tup, fastq_col),
                        reportfile=getattr(tup, report_col)
                        )
                )

    def plot_ccs_stats(self, variable, *,
                       trim_frac=0.005, bins=25, histogram_stat='count',
                       maxcol=None, panelsize=1.75):
        """Plot histograms of CCS stats for all runs.

        Parameters
        ----------
        variable : {'length', 'passes', 'quality'}
            Variable for which we get stats.
        trim_frac : float
            Trim this amount of the bottom and top fraction from the
            data before plotting. Useful if outliers greatly extend scale.
        bins : int
            Number of histogram binds
        histogram_stat : {'count', 'density'}
            Plot the count of CCSs or their density normalized for each run.
        maxcol : None or int
            Max number of columns in faceted plot.
        panelsize : float
            Size of each plot panel.

        Returns
        -------
        plotnine.ggplot.ggplot
            A panel of histograms.

        """
        df = (self.ccs_stats(variable)
              .assign(lower=lambda x: x[variable].quantile(trim_frac),
                      upper=lambda x: x[variable].quantile(1 - trim_frac),
                      trim=lambda x: ((x[variable] > x['upper']) |
                                      (x[variable] < x['lower']))
                      )
              .query('not trim')
              )

        npanels = len(df['name'].unique())
        if maxcol is None:
            ncol = npanels
        else:
            ncol = min(maxcol, npanels)
        nrow = math.ceil(npanels / ncol)

        p = (p9.ggplot(df, p9.aes(variable, y=f"..{histogram_stat}..")) +
             p9.geom_histogram(bins=bins) +
             p9.facet_wrap('~ name', ncol=ncol) +
             p9.theme(figure_size=(panelsize * ncol, panelsize * nrow),
                      axis_text_x=p9.element_text(angle=90,
                                                  vjust=1,
                                                  hjust=0.5)
                      ) +
             p9.ylab('number of CCSs')
             )

        return p

    def ccs_stats(self, variable):
        """Get CCS stats for all runs.

        Parameters
        ----------
        variable : {'length', 'passes', 'quality'}
            Variable for which we get stats.

        Returns
        -------
        pandas.DataFrame
            Data frame with columns of 'name' (holding run name) and the value
            of `variable` giving variable value for all CCSs.

        """
        try:
            attr = {'length': 'lengths',
                    'passes': 'passes',
                    'quality': 'quals'}[variable]
        except KeyError:
            raise ValueError(f"invalid `variable` of {variable}")

        df_list = []
        for summary in self.summaries:
            df_list.append(pd.DataFrame({'name': summary.name,
                                         variable: getattr(summary, attr)
                                         }))

        return (pd.concat(df_list, sort=False, ignore_index=True)
                .assign(name=lambda x: pd.Categorical(x['name'],
                                                      x['name'].unique(),
                                                      ordered=True))
                )

    def plot_zmw_stats(self, **kwargs):
        """Plot of ZMW stats for all runs.

        Parameters
        ----------
        ``**kwargs`` : dict
            Keyword arguments passed to :meth:`Summaries.zmw_stats`.

        Returns
        -------
        plotnine.ggplot.ggplot
            Stacked bar graph of ZMW stats for each run.

        """
        df = self.zmw_stats(**kwargs)

        p = (p9.ggplot(df, p9.aes(x='name', y='number', fill='status')) +
             p9.geom_col(position=p9.position_stack(reverse=True), width=0.8) +
             p9.theme(axis_text_x=p9.element_text(angle=90,
                                                  vjust=1,
                                                  hjust=0.5),
                      figure_size=(0.4 * len(df['name'].unique()), 2.5)
                      ) +
             p9.ylab('number of ZMWs') +
             p9.xlab('')
             )

        if len(df['status'].unique()) < len(CBPALETTE):
            p = p + p9.scale_fill_manual(CBPALETTE[1:])

        return p

    def zmw_stats(self, *, minfailfrac=0.01, groupsuccess=True):
        """Get ZMW stats for all runs.

        Parameters
        ----------
        minfailfrac : float
            Group failure categories with <= this fraction ZMWs for all runs.
        groupsuccess : bool
            Group all success categories into 'Success -- CCS generated'.

        Returns
        -------
        pandas.DataFrame
            Data frame with stats on ZMW status for all runs.

        """
        df = (pd.concat([summary.zmw_stats.assign(name=summary.name)
                         for summary in self.summaries],
                        sort=False, ignore_index=True)
              [['name', 'status', 'number', 'fraction']]
              .assign(max_fraction=lambda x: (x.groupby('status')
                                              ['fraction']
                                              .transform(max)
                                              ),
                      failed=lambda x: x['status'].str.contains('Failed'),
                      other=lambda x: ((x['max_fraction'] < minfailfrac) &
                                       x['failed'])
                      )
              )

        other_df = (df.query('other')
                    .groupby('name')
                    .aggregate({'number': sum, 'fraction': sum, 'failed': any})
                    .assign(status='Failed -- Other reason')
                    .reset_index()
                    .assign(max_fraction=lambda x: (x.groupby('status')
                                                    ['fraction']
                                                    .transform(max)
                                                    ))
                    )

        df = (df
              .query('not other')
              .drop(columns='other')
              .merge(other_df, how='outer')
              )

        if groupsuccess:
            success_df = (df
                          .query('status.str.match("^Success")')
                          .groupby('name')
                          .aggregate({'number': sum, 'fraction': sum,
                                      'failed': any, 'max_fraction': max})
                          .reset_index()
                          .assign(status='Success -- CCS generated')
                          )
            df = (df
                  .query('not status.str.match("^Success")')
                  .merge(success_df, how='outer')
                  )

        # order columns
        names = [summary.name for summary in self.summaries]
        statuses = (df
                    .sort_values(['failed', 'max_fraction'],
                                 ascending=[True, False])
                    ['status']
                    .unique()
                    )
        df = (df
              .assign(name=lambda x: pd.Categorical(x['name'],
                                                    names,
                                                    ordered=True),
                      status=lambda x: pd.Categorical(x['status'],
                                                      statuses,
                                                      ordered=True),
                      )
              .sort_values(['name', 'status'])
              .drop(columns=['max_fraction', 'failed'])
              .reset_index(drop=True)
              )

        return df


def report_to_stats(reportfile, *, stat_type='zmw'):
    """Parse statistics from report file.

    Parameters
    ----------
    reportfile : str
        Report file generatedy by ``ccs`` using ``--reportFile`` flag.
    stat_type : {'zmw', 'subread'}
        Get stats on ZMWs or subreads.

    Returns
    -------
    pandas.DataFrame
        A data frame with the statistics.

    Example
    -------
    First an example of the ``ccs`` version 3.1.0 output:

    >>> reportfile = tempfile.NamedTemporaryFile(mode='w')
    >>> _ = reportfile.write(textwrap.dedent('''
    ...     ZMW Yield
    ...     Success -- CCS generated,242220,45.57%
    ...     Failed -- Below SNR threshold,0,0.00%
    ...     Failed -- No usable subreads,4877,0.92%
    ...     Failed -- Insert size too long,35,0.00%
    ...     Failed -- Insert size too small,0,0.00%
    ...     Failed -- Not enough full passes,180620,33.98%
    ...     Failed -- Too many unusable subreads,1,0.00%
    ...     Failed -- CCS did not converge,23,0.00%
    ...     Failed -- CCS below minimum predicted accuracy,103801,19.53%
    ...     Failed -- Unknown error during processing,0,0.00%
    ...
    ...
    ...     Subread Yield
    ...     Success - Used for CCS,10972010,89.06%
    ...     Failed -- Below SNR threshold,0,0.00%
    ...     Failed -- Alpha/Beta mismatch,171,0.00%
    ...     Failed -- Below minimum quality,0,0.00%
    ...     Failed -- Filtered by size,144209,1.17%
    ...     Failed -- Identity too low,2745750,22.29%
    ...     Failed -- Z-Score too low,0,0.00%
    ...     Failed -- From ZMW with too few passes,274296,2.23%
    ...     Failed -- Other,928871,7.54%
    ...     ''').lstrip())
    >>> reportfile.flush()
    >>> report_to_stats(reportfile.name)
                                               status  number percent  fraction
    0                        Success -- CCS generated  242220  45.57%    0.4557
    1                   Failed -- Below SNR threshold       0   0.00%    0.0000
    2                    Failed -- No usable subreads    4877   0.92%    0.0092
    3                  Failed -- Insert size too long      35   0.00%    0.0000
    4                 Failed -- Insert size too small       0   0.00%    0.0000
    5                Failed -- Not enough full passes  180620  33.98%    0.3398
    6            Failed -- Too many unusable subreads       1   0.00%    0.0000
    7                  Failed -- CCS did not converge      23   0.00%    0.0000
    8  Failed -- CCS below minimum predicted accuracy  103801  19.53%    0.1953
    9       Failed -- Unknown error during processing       0   0.00%    0.0000
    >>> reportfile.close()

    Now an example of the ``ccs`` version 3.4.1 output:

    >>> reportfile = tempfile.NamedTemporaryFile(mode='w')
    >>> _ = reportfile.write(textwrap.dedent('''
    ...     ZMW Yield
    ...     Success (without retry) -- CCS generated,202033,29.44%
    ...     Success (with retry)    -- CCS generated,2,0.00%
    ...     Failed -- Below SNR threshold,0,0.00%
    ...     Failed -- No usable subreads,2093,0.31%
    ...     Failed -- Insert size too long,10,0.01%
    ...     Failed -- Insert size too small,79,0.01%
    ...     Failed -- Not enough full passes,343876,50.12%
    ...     Failed -- Too many unusable subreads,0,0.00%
    ...     Failed -- CCS did not converge,0,0.00%
    ...     Failed -- CCS below minimum predicted accuracy,138083,20.12%
    ...     Failed -- Unknown error during processing,0,0.00%
    ...
    ...
    ...     ''').lstrip())
    >>> reportfile.flush()
    >>> report_to_stats(reportfile.name)  # doctest: +NORMALIZE_WHITESPACE
                                               status  number percent  fraction
    0        Success (without retry) -- CCS generated  202033  29.44%    0.2944
    1        Success (with retry)    -- CCS generated       2   0.00%    0.0000
    2                   Failed -- Below SNR threshold       0   0.00%    0.0000
    3                    Failed -- No usable subreads    2093   0.31%    0.0031
    4                  Failed -- Insert size too long      10   0.01%    0.0001
    5                 Failed -- Insert size too small      79   0.01%    0.0001
    6                Failed -- Not enough full passes  343876  50.12%    0.5012
    7            Failed -- Too many unusable subreads       0   0.00%    0.0000
    8                  Failed -- CCS did not converge       0   0.00%    0.0000
    9  Failed -- CCS below minimum predicted accuracy  138083  20.12%    0.2012
    10      Failed -- Unknown error during processing       0   0.00%    0.0000
    >>> reportfile.close()

    """
    reportmatch = re.compile('^ZMW Yield\n(?P<zmw>(.+\n)+)\n\n'
                             '(?:Subread Yield\n(?P<subread>(.+\n)+))?$')
    with open(reportfile) as f:
        report = f.read()
    m = reportmatch.search(report)
    if not m:
        raise ValueError(f"Cannot match report in {reportfile}:\n{report}")

    return (pd.read_csv(io.StringIO(m.group(stat_type)),
                        names=['status', 'number', 'percent'])
            .assign(fraction=lambda x: (x.percent.str.slice(None, -1)
                                        .astype(float) / 100))
            )


def get_ccs_stats(fastqfile, *, pass_tag='np', qual_tag='rq'):
    """Get basic statistics about circular consensus sequences.

    Parameters
    ----------
    fastqfile : str
        FASTQ file with circular consensus sequences, generated from BAM output
        of ``ccs`` with ``samtools bam2fq -T np,rq {bamfile} > {fastqfile}``.
        Can be gzipped.
    pass_tag : str
        Tag in FASTQ file giving number of passes.
    qual_tag : str
        Tag in FASTQ file giving predicted sequence quality.

    Returns
    -------
    collections.namedtuple
        The 3-tuple `(passes, quals, lengths)`, which contains numpy arrays
        giving number of passes, qualities, and lengths for sequences in
        `fastqfile`.

    Example
    -------
    >>> fastqfile = tempfile.NamedTemporaryFile(mode='w')
    >>> _ = fastqfile.write(textwrap.dedent('''
    ...   @m54228_190118_102822/4194373/ccs np:i:18 rq:f:0.999998
    ...   GGTACCACACTCTTTCCCTACACGACGCTCTGCCGATCTCGGCCATTACGTGTTTTATCTA
    ...   +
    ...   ~~~~{~~~~~~~c~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~i~~~~~~~~
    ...   @m54228_190118_102822/4194374/ccs np:i:51 rq:f:1
    ...   GCACGGCGTCACACTTTGCTATGCCATAGCATGTTTATCCATAAGATTAGCGGATCCTACCT
    ...   +
    ...   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    ...   ''').lstrip())
    >>> fastqfile.flush()
    >>> get_ccs_stats(fastqfile.name)  # doctest: +NORMALIZE_WHITESPACE
    CCS_Stats(passes=array([18, 51]),
              quals=array([0.999998, 1.      ]),
              lengths=array([61, 62]))
    >>> fastqfile.close()

    """
    matchers = {'pass': re.compile(r'(?:^|\s)'  # start of str or space
                                   rf"{pass_tag}:i:(?P<pass>\d+)"
                                   r'(?:\s|$)'  # end of str or space
                                   ),
                'qual': re.compile(r'(?:^|\s)'  # start of str or space
                                   rf"{qual_tag}:f:(?P<qual>\d+(?:\.\d+)?)"
                                   r'(?:\s|$)'  # end of str or space
                                   ),
                }
    arrays = {'pass': [], 'qual': [], 'length': []}
    for rec in pysam.FastxFile(fastqfile):
        for mtype, matcher in matchers.items():
            m = matcher.search(rec.comment)
            if not m:
                raise ValueError(f"no `{mtype}_tag`:\n{rec}\n\n{rec.comment}")
            arrays[mtype].append(m.group(mtype))
        arrays['length'].append(len(rec.sequence))

    CCS_Stats = collections.namedtuple('CCS_Stats', 'passes quals lengths')
    return CCS_Stats(passes=numpy.array(arrays['pass'], dtype='int'),
                     quals=numpy.array(arrays['qual'], dtype='float'),
                     lengths=numpy.array(arrays['length'], dtype='int'),
                     )


if __name__ == '__main__':
    import doctest
    doctest.testmod()
