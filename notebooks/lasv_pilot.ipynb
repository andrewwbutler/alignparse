{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lassa virus glycoprotein PacBio sequencing \n",
    "This example shows how to use [alignparse](https://jbloomlab.github.io/alignparse/) to process circular consensus sequences that map to multiple different targets. Here, our two targets are a wildtype and a codon optimized sequence for the Lassa virus (LASV) glycoprotein from the Josiah strain. For such targets we do not expect large internal deletions, so we use alignment settings optimized for codon-level mutations as these will be the settings used when analyzing mutant LASV GP sequences in later experiments.\n",
    "\n",
    "Here we analyze a snippet of the full data set of circular consensus sequences so that the example is small and fast.\n",
    "\n",
    "In the other included example notebooks ([RecA deep mutational scanning libraries](https://jbloomlab.github.io/alignparse/recA_DMS.html) and [Single-cell virus sequencing](https://jbloomlab.github.io/alignparse/flu_virus_seq_example.html)), we align and parse the PacBio reads using the single [align_and_parse](https://jbloomlab.github.io/alignparse/alignparse.targets.html#alignparse.targets.Targets.align_and_parse) function. Here we use separate functions to do the aligning and parsing steps. This illustrates an additional use case and shows how this package could be used to parse alignments generated elsewhere as long as they have a [cs tag](https://lh3.github.io/minimap2/minimap2.html#10) and are in the SAM file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for analysis\n",
    "Import necessary Python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "import Bio.SeqIO\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "import pysam\n",
    "\n",
    "import alignparse.ccs\n",
    "import alignparse.minimap2\n",
    "import alignparse.targets\n",
    "import alignparse.cs_tag\n",
    "import alignparse.consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppress warnings that clutter output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory for output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = './output_files/'\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color palette for plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBPALETTE = ('#999999', '#E69F00', '#56B4E9', '#009E73')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target amplicons\n",
    "We have performed sequencing of several LASV GP amplicons that include the glycoprotein sequence along with a PacBio index and several other features. Here we analyze reads mapping to two of these amplicons.\n",
    "The amplicons are defined in [Genbank Flat File format](https://www.ncbi.nlm.nih.gov/genbank/samplerecord/).\n",
    "First, let's just look at the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file_names = ['LASV_Josiah_WT', 'LASV_Josiah_OPT']\n",
    "\n",
    "targetfiles = [f\"input_files/{target_file_name}.gb\" for target_file_name in target_file_names]\n",
    "\n",
    "\n",
    "for targetfile in targetfiles:\n",
    "    with open(targetfile) as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with the Genbank files giving the sequences of the amplicons, we have a YAML file specifying how to filter and parse alignments to these amplicons.\n",
    "\n",
    "Below is the text of the YAML file.\n",
    "\n",
    "Additional information about these filters can be found in the [RecA deep mutational scanning libraries](https://jbloomlab.github.io/alignparse/recA_DMS.html) example notebook or the [Targets](https://jbloomlab.github.io/alignparse/alignparse.targets.html#alignparse.targets.Targets) documentation. \n",
    "\n",
    "A filter setting of `null` indicates this filter is not applied. When filters are missing for a feature, they are automatically set to zero.\n",
    "\n",
    "Here we filter the `gene` based on `mutation_op_counts` by setting the `mutation_nt_counts` filter for the `gene` to `null`. Although we do not expect these sequences to have large indels, we want to confirm this. Filtering on mutation \"operations\" allows us to retain sequences with large indels by only filtering on the number of indels, not the number of nucleotides inserted or deleted. Overall, this example uses very loose filters to allow us to do further analyses of the types of mutations that are arising in these samples.\n",
    "\n",
    "The YAML file also specifies what information is parsed from alignments that are not filtered out.\n",
    "As you can see, for some features we parse the mutations or the full sequence of the feature, along with the accuracy of that feature in the sequencing query (computed from the Q-values). \n",
    "\n",
    "As seen below, we can use YAML syntax to apply one set of filters to multiple targets. Here, we apply the same filters to both targets, but this is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasv_parse_specs_file = 'input_files/lasv_feature_parse_specs.yaml'\n",
    "with open(lasv_parse_specs_file) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the amplicons in `feature_parse_specs` into a [Targets](https://jbloomlab.github.io/alignparse/alignparse.targets.html#alignparse.targets.Targets) object, specifying the features that we require the target to contain. The [Targets](https://jbloomlab.github.io/alignparse/alignparse.targets.html#alignparse.targets.Targets) in this example have more features specified in their Genbank files than we want to parse, so we set `allow_extra_features` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = alignparse.targets.Targets(seqsfile=targetfiles,\n",
    "                  feature_parse_specs=lasv_parse_specs_file,\n",
    "                  allow_extra_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the [targets.feature_parse_specs](https://jbloomlab.github.io/alignparse/alignparse.targets.html#alignparse.targets.Targets.feature_parse_specs), we now see that the previously unspecified specs have been filled in with the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets.feature_parse_specs('yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the [Targets](https://jbloomlab.github.io/alignparse/alignparse.targets.html#alignparse.targets.Targets). All features specified in the targets' Genbank files will be annotated, even if they are not in `feature_parse_specs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = targets.plot(ax_width=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PacBio CCSs\n",
    "We will align PacBio circular consensus sequences (CCSs) to the target.\n",
    "First, we want to look at the CCSs.\n",
    "A FASTQ file with these CCSs along with an associated report file were generated using the PacBio `ccs` program (see [here](https://github.com/PacificBiosciences/ccs) for details on `ccs`) using commands like the following (generates report file and BAM of CCSs):\n",
    "\n",
    "    ccs --minLength 50 --maxLength 5000 \\\n",
    "        --minPasses 3  --minPredictedAccuracy 0.999 \\\n",
    "        --reportFile lasv_pilot_report.txt \\\n",
    "        --polish --numThreads 16 \\\n",
    "        lasv_pilot_subreads.bam lasv_pilot_ccs.bam\n",
    "        \n",
    "The BAM file was then converted to a FASTQ file using [samtools](http://www.htslib.org/) with flags to retain the number of passes (`np`) and read quality (`rq`). Here we convert the BAM file to a gzipped FASTQ file to demonstrate the use of compressed files:\n",
    "\n",
    "    samtools bam2fq -T np,rq lasv_pilot_ccs.bam | gzip > lasv_pilot_ccs.fastq.gz\n",
    "    \n",
    "Here is a data frame with the resulting FASTQ and BAM files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_names = ['lasv_pilot']\n",
    "ccs_dir = 'input_files'\n",
    "file_name = 'lasv_example'\n",
    "\n",
    "pacbio_runs = pd.DataFrame(\n",
    "            {'name': run_names,\n",
    "             'report': [f\"{ccs_dir}/{name}_report.txt\" for name in run_names],\n",
    "             'fastq': [f\"{ccs_dir}/{file_name}_ccs.fastq.gz\"]\n",
    "             })\n",
    "\n",
    "pacbio_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a [Summaries](https://jbloomlab.github.io/alignparse/alignparse.ccs.html#alignparse.ccs.Summaries) object for these CCSs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_summaries = alignparse.ccs.Summaries(pacbio_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot how many ZMWs yielded CCSs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ccs_summaries.plot_zmw_stats()\n",
    "_ = p.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_summaries.zmw_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics on the CCSs (length, number of subread passes, accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stat in ['length', 'passes', 'accuracy']:\n",
    "    if ccs_summaries.has_stat(stat):\n",
    "        p = ccs_summaries.plot_ccs_stats(stat)\n",
    "        _ = p.draw()\n",
    "    else:\n",
    "        print(f\"No information available on CCS {stat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align CCSs to target\n",
    "Now we use [minimap2](https://github.com/lh3/minimap2) to align the CCSs to the target.\n",
    "\n",
    "First, we create a [Mapper](https://jbloomlab.github.io/alignparse/alignparse.minimap2.html#alignparse.minimap2.Mapper) object to run [minimap2](https://github.com/lh3/minimap2), using the options for codon-level deep mutational scanning (specified by [alignparse.minimap2.OPTIONS_CODON_DMS](https://jbloomlab.github.io/alignparse/alignparse.minimap2.html#alignparse.minimap2.OPTIONS_CODON_DMS)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = alignparse.minimap2.Mapper(alignparse.minimap2.OPTIONS_CODON_DMS)\n",
    "\n",
    "print(f\"Using `minimap2` {mapper.version} with these options:\\n\" +\n",
    "      ' '.join(mapper.options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this mapper to do the alignments to a SAM file.\n",
    "First, add the names of the desired alignment files to our data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pacbio_runs = pacbio_runs.assign(alignments=lambda x: outdir + x['name'] + '_alignments.sam')\n",
    "\n",
    "pacbio_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run [targets.align](https://jbloomlab.github.io/alignparse/alignparse.targets.html#alignparse.targets.Targets.align) using the mapper to actually align the FASTQ queries to the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in pacbio_runs.itertuples(index=False):\n",
    "    print(f\"Aligning {tup.fastq} to create {tup.alignments}...\")\n",
    "    targets.align(queryfile=tup.fastq,\n",
    "                  alignmentfile=tup.alignments,\n",
    "                  mapper=mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These SAM files now contain the alignments along with the [cs tag](https://github.com/lh3/minimap2#cs). \n",
    "\n",
    "An example [cs tag](https://github.com/lh3/minimap2#cs) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in pacbio_runs['alignments'][:1]:\n",
    "    with pysam.AlignmentFile(fname) as f:\n",
    "        a = next(f)\n",
    "        print(f\"First alignment in {fname} has `cs` tag:\\n\" + a.get_tag('cs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the alignments\n",
    "Now we use [Targets.parse_alignments](https://jbloomlab.github.io/alignparse/alignparse.targets.html#alignparse.targets.Targets.parse_alignment) to parse the SAM files to get the information we specified for return.\n",
    "This function returns a data frame (`readstats`) on the overall parsing stats, plus dicts keyed by the names of each target in [Targets](https://jbloomlab.github.io/alignparse/alignparse.targets.html#alignparse.targets.Targets) giving data frames of the aligned and filtered reads. Here we return the `aligned` and `filtered` reads as dictionaries of data frames. \n",
    "\n",
    "The `aligned` and `filtered` read information can instead be returned as CSV files containing these data frames by setting the `to_csv` argument to `True`. Note: When using the combined [Targets.align_and_parse](https://jbloomlab.github.io/alignparse/alignparse.targets.html#alignparse.targets.Targets.align_and_parse) function as in the other example notebooks ([RecA DMS libraries](https://jbloomlab.github.io/alignparse/recA_DMS.html) and [Single-cell virus sequencing](https://jbloomlab.github.io/alignparse/flu_virus_seq_example.html)), these CSV files will always be created, even if `to_csv` is `False` and the [align_and_parse](https://jbloomlab.github.io/alignparse/alignparse.targets.html#alignparse.targets.Targets.align_and_parse) function is returning `aligned` and `filtered` as dictionaries of data frames in its final output.\n",
    "\n",
    "Here we only have one PacBio run, but in practice we will often have multiple. As such, our example shows how to concatenate the `readstats`, `aligned`, and `filtered` data frames for each PacBio run and then look at the data frames together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readstats = []\n",
    "aligned = {targetname: [] for targetname in targets.target_names}\n",
    "filtered = {targetname: [] for targetname in targets.target_names}\n",
    "\n",
    "for run in pacbio_runs.itertuples():\n",
    "    \n",
    "    print(f\"Parsing PacBio run {run.name}\")\n",
    "    run_readstats, run_aligned, run_filtered = targets.parse_alignment(run.alignments, filtered_cs=True)\n",
    "    \n",
    "    # when concatenating add the run name to keep track of runs for results\n",
    "    readstats.append(run_readstats\n",
    "                     .assign(run_name=run.name)\n",
    "                     )\n",
    "    for targetname in targets.target_names:\n",
    "        aligned[targetname].append(run_aligned[targetname]\n",
    "                                   .assign(run_name=run.name)\n",
    "                                   )\n",
    "        filtered[targetname].append(run_filtered[targetname]\n",
    "                                    .assign(run_name=run.name)\n",
    "                                    )\n",
    "        \n",
    "# now concatenate the data frames for each run\n",
    "readstats = pd.concat(readstats, ignore_index=True, sort=False)\n",
    "for targetname in targets.target_names:\n",
    "    aligned[targetname] = pd.concat(aligned[targetname], ignore_index=True, sort=False)\n",
    "    filtered[targetname] = pd.concat(filtered[targetname], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets look at the read stats:\n",
    "\n",
    "From the known composition of the library, there should be more `LASV_Josiah_OPT` reads than `LASV_Josiah_WT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "readstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    ggplot(readstats, aes('category', 'count')) +\n",
    "    geom_bar(stat='identity') +\n",
    "    facet_wrap('~ run_name', nrow=1) +\n",
    "    theme(axis_text_x=element_text(angle=90),\n",
    "          figure_size=(1.5 * len(pacbio_runs), 2.5)\n",
    "          )\n",
    "    )\n",
    "_ = p.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the information on the filtered reads.\n",
    "This is a bigger data frame, so we just look at the first few lines for the first target (of which there is only one anyway):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered[targets.target_names[0]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for targetname in targets.target_names:\n",
    "    target_filtered = filtered[targetname]\n",
    "    nreasons = target_filtered['filter_reason'].nunique()\n",
    "    p = (\n",
    "        ggplot(target_filtered, aes('filter_reason')) +\n",
    "        geom_bar() +\n",
    "        facet_wrap('~ run_name', nrow=1) +\n",
    "        labs(title=targetname) +\n",
    "        theme(axis_text_x=element_text(angle=90),\n",
    "              figure_size=(0.3 * nreasons * len(pacbio_runs), 2.5),\n",
    "              )\n",
    "        )\n",
    "    _ = p.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error filtering\n",
    "\n",
    "Before looking at the information for the validly aligned (not filtered) reads, it is important to get a sense of the error rate for these sequencing reads. \n",
    "\n",
    "These reads do not have random barcodes on the initial viral entry protein plasmids, but we can use the `gene_accuracy` information output from constructing the `ccs`s to examine accuracy. \n",
    "\n",
    "We will do this using a similar method to that implemented in the [RecA DMS libraries](https://jbloomlab.github.io/alignparse/recA_DMS.html) example notebook. However, here we will plot the graphs for each target. \n",
    "\n",
    "We anticipate excluding all CCSs for which the error rate for either the gene or barcode is $>10^{-4}$.\n",
    "We specify this cutoff below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate_floor = 1e-7  # error rates < this set to this\n",
    "error_cutoff = 1e-4\n",
    "\n",
    "for targetname in targets.target_names:\n",
    "    aligned[targetname] = (\n",
    "                  aligned[targetname]\n",
    "                  .assign(\n",
    "                          gene_error=lambda x: numpy.clip(1 - x['gene_accuracy'],\n",
    "                                                          error_rate_floor, None)\n",
    "                          )\n",
    "                  )\n",
    "    p = (\n",
    "         ggplot(aligned[targetname]\n",
    "                .melt(id_vars=['run_name'],\n",
    "                      value_vars=['gene_error'],\n",
    "                      var_name='feature_type', value_name='error rate'),\n",
    "                aes('error rate')) +\n",
    "         geom_histogram(bins=25) +\n",
    "         geom_vline(xintercept=error_cutoff,\n",
    "                    linetype='dashed',\n",
    "                    color=CBPALETTE[1]) +\n",
    "         facet_grid('~ feature_type') +\n",
    "         theme(figure_size=(3, 3)) +\n",
    "         labs(y=('number of CCSs'), title=(targetname)) +\n",
    "         scale_x_log10()\n",
    "         )\n",
    "\n",
    "    _ = p.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we store all reads with an error rate $<10^{-4}$ in new data frames for retained sequences. \n",
    "\n",
    "We will use these retained sequences for further analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retained = {targetname: [] for targetname in targets.target_names}\n",
    "for targetname in targets.target_names:\n",
    "    target_retained = aligned[targetname][aligned[targetname]['gene_error'] <= error_cutoff].reset_index(drop=True)\n",
    "    retained[targetname] = target_retained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "Now we can examine our data in more detail. \n",
    "\n",
    "We will only display a few columns so the example renders well in the documentation. First, let's look at the `query_name`, `gene_mutations`, and `index_sequence` columns for the first few entries in the `retained` data frame for each target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_columns = ['query_name', 'gene_mutations', 'index_sequence']\n",
    "for target_name in targets.target_names:\n",
    "    print(target_name)\n",
    "    display(retained[target_name][display_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen by the `index_sequence` columns, each target here has 2 or 3 different indices that map to it. These indicies indicate different samples. \n",
    "\n",
    "We can then split these data frames into sample-specific data frames based on the known starting index sequences for each target. We will store these data frames in a new dictionary, keyed by target and index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {'LASV_Josiah_WT': ['AGACAC', 'GGTATG'], 'LASV_Josiah_OPT': ['ACGACC', 'CTTCAC', 'GAGACG']}\n",
    "target_idx_retained = {}\n",
    "index_counts = {target: [] for target in indices}\n",
    "index_counts_dfs = {}\n",
    "for target_name in targets.target_names:\n",
    "    for index in indices[target_name]:\n",
    "        target_idx_retained[f\"{target_name}_{index}\"] = retained[target_name][retained[target_name]['index_sequence'] == index].reset_index(drop=True)\n",
    "        index_counts[f\"{target_name}\"].append((index, len(target_idx_retained[f\"{target_name}_{index}\"])))\n",
    "    index_counts[f\"{target_name}\"].append(('invalid', (len(retained[target_name]) - \n",
    "                                                          sum(idx_tup[1] for idx_tup in index_counts[target_name]))))\n",
    "    index_counts_dfs[target_name] = pd.DataFrame(index_counts[target_name], columns=['index', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process of making these separate data frames, we also kept track of how many reads for each target map to each index or don't map to an index (so have an 'invalid' index) and can now plot these counts. As seen below, only one sequence in this example has an invalid index and it maps to the `LASV_Josiah_OPT` target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_name in targets.target_names:\n",
    "    df = index_counts_dfs[target_name]\n",
    "    df['target'] = [target_name]*len(df)\n",
    "    id_order = ['invalid'] + df['index'][:-1].to_list()\n",
    "    df['index'] = pd.Categorical(df['index'], categories=id_order, ordered=True)\n",
    "    index_count_plot = (ggplot(df, aes(x='target', y='count', fill='index')) +\n",
    "                        geom_bar(stat='identity', position='stack') +\n",
    "                        scale_fill_manual(values=CBPALETTE) +\n",
    "                        theme(axis_text_x=element_text(angle=90, vjust=1, hjust=0.5),\n",
    "                        figure_size=(1, 2)) +\n",
    "                        ylab('Reads') +\n",
    "                        xlab('Target') +\n",
    "                        ggtitle('Reads per Sample Index'))\n",
    "    \n",
    "    _ = index_count_plot.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two target-specific data frames are now five index-specific data frames. Again we will display the `query_name`, `gene_mutations`, and `index_sequence` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for target_idx in target_idx_retained:\n",
    "    print(target_idx)\n",
    "    display(target_idx_retained[target_idx][display_columns].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add mutation info for the genes in these targets using [alignparse.consensus.add_mut_info_cols](https://jbloomlab.github.io/alignparse/alignparse.consensus.html#alignparse.consensus.add_mut_info_cols)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_idx in target_idx_retained:\n",
    "    target_idx_retained[target_idx] = alignparse.consensus.add_mut_info_cols(target_idx_retained[target_idx],\n",
    "                                                                              mutation_col='gene_mutations',\n",
    "                                                                              n_sub_col='n_gene_subs',\n",
    "                                                                              n_indel_col='n_gene_indels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the number of reads for each sample that has each number of substitutions or indels to get a sense of how many mutations are in these reads, if some smaples have more mutations than others, and if substitutions or indels are more prevalent in these sequences. \n",
    "\n",
    "With such a small sample snippet of the data, it is difficult to make any conclusions, but with a full dataset, this can provide important information about the mutational processes at work for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_cols = ['n_gene_subs', 'n_gene_indels']\n",
    "for target_idx in target_idx_retained:\n",
    "    target_idx_plot_muts = target_idx_retained[target_idx][mut_cols].melt()\n",
    "    mut_counts_plot = (\n",
    "                        ggplot(target_idx_plot_muts, aes('value')) +\n",
    "                        geom_bar() +\n",
    "                        facet_wrap('~ variable', ncol=2) +\n",
    "                        xlim(-0.5, 2.5) +\n",
    "                        labs(title=f\"{target_idx}\") +\n",
    "                        theme(axis_text_x=element_text(angle=90),\n",
    "                              figure_size=(3, 2.5),\n",
    "                              )\n",
    "    )\n",
    "    _ = mut_counts_plot.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
